# ДАГ для переноса и обработки информации из sources
Разработчик: Алексеев Роман<br />
Дата: 19.07.23

## Подготовка
Перед запуском ДАГа необходимо:
1. Установить Docker согласно [инструкции](https://docs.docker.com/engine/install/) на сайте.
2. Установить Apache Airflow согласно [инструкции](https://airflow.apache.org/docs/apache-airflow/stable/howto/docker-compose/index.html) на сайте.
3. В локальную директорию **dags** добавить файлы из директории *dags* из репозитория.
4. Запустить Apache Airflow при помощи ввода команды:<br />
   `docker compose up`<br />
   или<br />
   `sudo docker compose up`<br />
5. При помощи web-интерфейса Airflow, перейдя по ссылке [http://localhost:8080](http://localhost:8080), подключиться к БД **internship_3_db** и **internship_sources**, указав одноименные connection ID.<br />

Если все шаги выполнены верно, в списке ДАГов появится ДАГ: **transfer_dag**<br />

## Описание ДАГа
Разработанный ДАГ необходим для переноса информации из слоя sources в слой dds и одновременного удаления некорректных данных.<br />
ДАГ состоит из 5 шагов:
1. **start_step** - начальный пустой шаг.
2. **clean_step** - шаг очистки слоя dds. На данном шаге очищаются все сущности схемы dds, кроме stores. Если каких-то сущностей или самой схемы нет, они создаются.
3. **create_wrong_schema_step** - шаг создания схемы для некорректных данных. Т.к. при каждой выгрузке данных данная схема полностью очищается, то для этого используется пересоздание схемы.
4. **extract_data_step** - шаг переноса и обработки данных. Данный шаг вызывает функцию *dds_transfer*, импортируемую из файла dds_transfer.py.
5. **end_step** - конечный пустой шаг.<br />
Код SQL-запросов находится в файлах *clean_dds.sql* для **clean_step** и *create_wrong_dds.sql* для **create_wrong_schema_step** в директории *dags/sql*.

### Выгрузка данных
Выгрузка данных на шаге **extract_data_step** осуществляется при помощи PostgresHook. Выгружается вся информация из всех сущностей слоя sources: product, stock, brand, category, transaction.<br />
В связи с тем, что в sources находится неполная сущность transaction, у которой отсутствует поле *pos*, данные об этом загружаются из файла *transactions-stores.csv*. Файл *transactions-stores.csv* находится в директории: *dags/csv*. После загрузки данные объединяются с данными из transaction при помощи LEFT JOIN.

### Обработка данных
Обработка осуществляется при помощи вызова функций: *correct_brand*, *correct_category*, *correct_product*, *correct_stock*, *correct_transaction* для данных из соответствующих сущностей.<br />
Для работы с данными используется библиотека **Pandas**.<br />
Также использованы библиотеки **NumPy** и **datetime**.<br />
В данных функциях поля проверяются по критериям:
- Является ли содержимое числового поля неотрицательным числом.
- Не является ли объект пустым.
- Наличие дубликатов первичных ключей.
- Соответствие объектов полей дат формату дат.
- Существование внешних ключей.
- Разница между датой и сегодняшним днем менее 2 лет.<br />

Также реализована проверка на возраст даты для поля *available_on* сущности stock, но ее код закомментирован (строки 272-279), т.к. все записи в stock старше двух лет.

### Сохранение некорректных данных.
В каждой функции для обработки данных осуществляется сохранение некорректных записей с добавлением комментария об ошибке.<br />
Данные сохраняются в схеме wrong_data в соответствующих сущностях: product, stock, brand, category, transaction.<br />
Данные сущности не имеют первичных ключей, а также все поля имеют тип VARCHAR, чтобы было возможно сохранять некорректные данные с различными ошибками.

### Сохранение данных
Обработанные данные сохраняются в слой dds в соответствующие сущности.<br />
Для сохранения используется sqlalchemy_engine.

